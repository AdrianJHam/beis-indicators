{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto NUTS processing\n",
    "\n",
    "Here we relabel indicators using the nuts detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beis_indicators.utils.nuts_utils import auto_nuts2_uk\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataset(data_source):\n",
    "    '''\n",
    "    This function finds, for a data source, the processed csvs, and performs autonuts detection\n",
    "    \n",
    "    For now it will simply print the inferred specification for each csv\n",
    "    \n",
    "    Args:\n",
    "        -data source (str) is the folder storing indicators in /processed\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    path = f'../../data/processed/{data_source}'\n",
    "    \n",
    "    csv_files = [x for x in os.listdir(path) if 'csv' in x]\n",
    "    \n",
    "    for x in csv_files:\n",
    "        print(x)\n",
    "        auton = auto_nuts2_uk(pd.read_csv(os.path.join(path,x)))\n",
    "        \n",
    "        print(set(auton['nuts_year_spec']))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nuts_test_processed():\n",
    "    '''\n",
    "    Finds all csv folders in the processed folder with a yaml file (ie merged indicators)\n",
    "    Performs the test\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    to_check = []\n",
    "    \n",
    "    for folder in os.listdir('../../data/processed/'):\n",
    "        \n",
    "        if os.path.isdir(f'../../data/processed/{folder}')==True:\n",
    "            \n",
    "            #We assume that folders with yamls have been processed\n",
    "            yamls = [x for x in os.listdir(f'../../data/processed/{folder}') if '.yaml' in x]\n",
    "            \n",
    "            #This is not always the case though\n",
    "            \n",
    "            try:\n",
    "            \n",
    "                for x in yamls:\n",
    "\n",
    "                    csv = re.sub('.yaml','.csv',x)\n",
    "\n",
    "                    table = pd.read_csv(f'../../data/processed/{folder}/{csv}',index_col=None)\n",
    "                    \n",
    "                    #Remove unnecessary indices\n",
    "                    table = table[[x for x in table.columns if 'Unnamed' not in x]]\n",
    "\n",
    "                    #Autonuts\n",
    "                    autonuts = auto_nuts2_uk(table)\n",
    "                    \n",
    "                    #Save\n",
    "                    autonuts.to_csv(f'../../data/processed/{folder}/{csv}',index=False)\n",
    "\n",
    "                    print(autonuts.head())\n",
    "                    \n",
    "            except:\n",
    "                print('old schema')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_test_processed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
